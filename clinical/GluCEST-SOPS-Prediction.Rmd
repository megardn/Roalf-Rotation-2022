---
title: "GluCEST-SOPS-Prediction"
output: html_document
---

```{r Install/Load packages, echo=FALSE, message=FALSE, warning=FALSE}
#load packages
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(tidyverse, ggplot2, ggpubr, ggrepel, skimr, lubridate, tidyr, data.table, car, ggpubr, corrplot, lme4, lmerTest, report, DescTools, daff, GGally, atable, glmnet, ppcor, plot3D, plot3Drgl)
```



# Compile Scan Lists

*Code originally from `scan_list_comp.Rmd`*

Compile lists of all GluCEST scans.

## Load & Clean Lists

7T list from David (up to ~ summer 2019)

```{r 7t list}
glu_old <- read.csv("data/7t_dates.csv", na.strings = "") # read in 7T list from David (up to ~ summer 2019)
summary(glu_old)

# clean up formatting
glu_old <- glu_old %>%
  mutate(BBLID=as.character(BBLID),
  X7T_date = gsub(",.*","", X7T_date), 
  Terra.7T_date = as.Date(X7T_date,format ="%m/%d/%y"),
  ONM.7T_date = as.Date(ONM_7T_date,format ="%m/%d/%y"),
  ONM.SCANID=as.character(ONM_SCANID)) %>%
  rename(Terra.SCANID=Terra_SCANID) %>%
 dplyr::select(-X7T_date, -ONM_7T_date, -ONM_SCANID)

# make long
glu_old.long <- glu_old %>% pivot_longer(2:5, names_sep = '[.]', names_to=c("scanner", ".value")) %>%
  drop_na("7T_date")
```

7T list from Arianna's LongGluCEST study (pulled April 2022)

``` {r longglucest}
glu_ar <- read.csv("data/longglucest_scans.csv", header=T) # read in 7T list from Arianna LongGluCEST study (pulled April 2022)
summary(glu_ar)

#clean up formatting
glu_ar <- glu_ar %>%
  mutate(BBLID=as.character(BBLID),
         base_7t = as.Date(base_7t,format ="%m/%d/%y"),
         follow_7t = as.Date(follow_7t,format ="%m/%d/%y")) %>%
 dplyr::select(-baseline_clinical)

# make long
glu_ar.long <- gather(glu_ar, scanner, "7T_date", base_7t:follow_7t, factor_key=TRUE) %>%
  drop_na("7T_date") %>%
  mutate(scanner= fct_collapse(scanner, Terra = c("base_7t", "follow_7t")))
```

7T list from Heather's Aging study

``` {r aging}
glu_age <- read.csv("data/7tglucestage_scans.csv", header=T) # read in 7T list from Heather Aging study (pulled April 2022)

#clean up
glu_age <- glu_age %>%
  transmute(BBLID=as.character(BBLID),
         "7T_date" = as.Date(DOSCAN,format ="%m/%d/%y"),
         scanner = as.factor("Terra"),
         SCANID=as.character(SCANID))
summary(glu_age)
```

Join all lists:

```{r}
#join long versions of old and Longitudinal scan lists
long1 <- merge(x=glu_old.long, y=glu_ar.long, by=c("BBLID", "7T_date", "scanner"),all=TRUE)
str(long1)

#join in Age study scan list
all_7t.long <- merge(x=long1, y=glu_age, by=c("BBLID", "7T_date", "scanner", "SCANID"), all=TRUE)
all_7t.long <- all_7t.long %>% rename(date_7t = "7T_date")
str(all_7t.long)

dup <- duplicated(all_7t.long[,1:2])
any(dup) #no duplicates!
```

Next make a wide version to easily add in clinical/subject-level data.

``` {r}
all_7t.count <- all_7t.long %>%
  group_by(BBLID) %>%
  arrange(all_7t.long$date_7t) %>%
  mutate(count = as.character(row_number(BBLID)),
         scanner=as.factor(scanner)) %>%
  ungroup() # add counts
all_7t.wide <- pivot_wider(all_7t.count, id_cols=BBLID, names_from = count, values_from=c(date_7t, scanner, SCANID)) # pivot
colnames(all_7t.wide)[2:ncol(all_7t.wide)] <- paste("scan", colnames(all_7t.wide[,c(2:ncol(all_7t.wide))]), sep = "_") #rename cols

# #write final list to csv
# write.csv(all_7t.wide, "data/all_7T_april22.csv", row.names=FALSE, na="")
# save(all_7t.wide, file="data/all_7T_april22.Rdata")

n_distinct(all_7t.wide$BBLID)
```

Load diagnosis data from oracle ID and remove 22q subj

```{r}
#load diagnosis data
redcap <- read.csv("data/oracle_diagnoses_all.csv", header = TRUE, stringsAsFactors = F, na = c("", "null", "..", ".")) %>% 
 dplyr::select(BBLID, DODIAGNOSIS, HSTATUS, AGEONSET_CLINICRISK | contains("AXIS1_")) %>% #get manageable subset of data
  mutate(DODIAGNOSIS = as.Date(DODIAGNOSIS),
         BBLID=as.factor(BBLID))


#make list of 22q subj
q22 <- subset(redcap, HSTATUS == "22q",select = BBLID) %>% unique()

#remove 22q participants from scan list, that way it'll apply to all subsequent merges w/ clinical data
all_7t.wide <- all_7t.wide %>% subset(!(BBLID %in% q22$BBLID)) %>% as.data.frame()#drop 22q sub
all_7t.long <- all_7t.long %>% subset(!(BBLID %in% q22$BBLID)) %>% as.data.frame()#drop 22q sub
```

There are `r length(unique(all_7t.wide$BBLID))` (197) unique subjects who have 7T scans, excluding 22q pts ID'd from Kosha's RedCap data.



# SIPS/SOPS

Load SIPS data

```{r}
#load SIPS
sips <- fread("data/oracle_sips_all.csv", na.strings="null", header=TRUE)
  #mutate(DOSIPS = as.Date(DOSIPS),
         #bblid = as.factor(bblid))
sips$BBLID <- as.factor(sips$BBLID)
skim(sips)
```

Now for our outcome of interest, SIPS/SOPS scores. First filtering by completion. 

```{r}
#list sops items
plist <- c("P1", "P2", "P3", "P4", "P5")
nlist <- c("N1", "N2", "N3", "N4", "N5", "N6")
dlist <- c("D1", "D2", "D3", "D4")
glist <- c("G1", "G2", "G3", "G4")
sops.item.list <- c(plist, nlist, dlist, glist)

#drop missing sops items
sips_filt <- sips %>% drop_na(c(plist))
#sum(is.na(sips_filt[,c(sops.item.list)]))
length(unique(sips_filt$BBLID))
```

Some subjects have multiple assessments on one day (one from proband one from family, etc); need to be sure to pick only `TYPE == "COMBINED"` per discussion with David. If no combined, pick proband.

```{r}
#if subj has more than one assessment for same day,dplyr::select Combined 
sips_filt<- sips_filt %>% mutate(TYPE = as.factor(TYPE))
levels(sips_filt$TYPE) 
sips_filt$TYPE <- fct_collapse(sips_filt$TYPE, "Proband" = c("Proband", "proband", "P", "FP", "IP"), "Combined"=c("Combined", "FPC")) #combine all proband
sips_filt$TYPE <- factor(sips_filt$TYPE, levels = c("Combined", "Proband", "Collateral"))

#group data todplyr::select correct type (defined as lowest ordered level) - also cleaning up
sips_filt2 <- sips_filt %>%
  group_by(BBLID, DOSIPS) %>%
  arrange(TYPE) %>%
  slice(c(1)) %>%
  ungroup() %>%
 dplyr::select(-SIPS_SOURCEID, -SOURCE_PROJECT) %>%
  mutate(DOSIPS=as.Date(DOSIPS))

length(unique(sips_filt2$BBLID)) #confirm no subjects deleted
skim(sips_filt2)
```

Calculate SOPS scores by summing within each subscale (seems to be valid metric based on clinicaltrials.gov)

```{r, warning=FALSE}
#calculate sops scores
sips_scored<- sips_filt2 %>% mutate(sops_p = rowSums(across(plist), na.rm=F),
                                  sops_n = rowSums(across(nlist), na.rm=F),
                                  sops_d = rowSums(across(dlist), na.rm=F),
                                  sops_g = rowSums(across(glist), na.rm=F),
                                  sops_tot = rowSums(across(c(sops_p, sops_n, sops_d, sops_g), na.rm=F)))

#also dropping `3456` cols (and maybe GAF_PCTCHG?) since they don't seem to mean anything or be useful and it would be better to recalculate them anyway
#aksi dropping rater
sips_scored <- sips_scored %>%dplyr::select(-VISITNUM, -RATER, -REVIEW, -POS_345, -POS_6, - NEG_3456, -DIS_3456, - GEN_3456) %>% as.data.frame()

head(sips_scored)
```

Merging into long scanlist and filtering for scans with baseline w/in 1 yr and at least one follow-up 1yr or more later

```{r}
sips_scan_long <- inner_join(all_7t.long, sips_scored, by="BBLID")
head(sips_scan_long)

#calc diff from each 7T scan (negative values -> dx before 7t)
sips_scan_long <- sips_scan_long %>%
  mutate(sips_diff_days = as.numeric(difftime(DOSIPS,date_7t, units = "days")),
         sips_diff_yrs = round((as.numeric(difftime(DOSIPS,date_7t, units = "weeks"))/52.25)/.5)*.5) %>% #time diff rounded to half-yr
  rename(date7t=date_7t)
         
sip.pre.scan_l <-  which(sips_scan_long$sips_diff_days <= 364 & sips_scan_long$sips_diff_days >= -365)
sip.post.scan_l <-  which(sips_scan_long$sips_diff_days > 364)

sips_scan_long.lab <- sips_scan_long %>%
  mutate(scan.time = case_when(row_number() %in% sip.pre.scan_l ~ "base", 
                                row_number() %in% sip.post.scan_l ~ "end"),) %>% #label every sops timepoint relative to each scan
  filter(!is.na(scan.time)) %>% #drop sops that don't meet criteria for base or endpoint 
  group_by(BBLID, date7t) %>%
  arrange(abs(sips_diff_days)) %>%
  mutate(row = row_number()) %>%
  filter(!(scan.time=="base" & row > 1)) %>% #if subject has more than one baseline SOPS, just get closest to scan
  ungroup() %>%
 dplyr::select(-row)

table(as.factor(sips_scan_long.lab$scan.time))
n_unique(sips_scan_long.lab$BBLID)

#drop scans with less than 2 timepoints
scanlist_clean <- sips_scan_long.lab %>%
  group_by(BBLID, date7t) %>%
  arrange(abs(sips_diff_days)) %>%
  filter(first(scan.time)=="base" & n() >= 2) %>% #only keep BBLID-scan pairs with 2+ timepoints, the first being baseline
  ungroup() %>%
  group_by(BBLID, date7t, scan.time) %>%
  mutate(row = row_number(),
         scan.time=paste(scan.time,as.character(row), sep="."), #number endpoints if subj has more than one
         observation = paste(as.character(BBLID), as.character(date7t), scan.time)) %>% #add indicator for observation
  ungroup() %>%
 dplyr::select(-row)

table(as.factor(scanlist_clean$scan.time))
n_unique(scanlist_clean$BBLID)
skim(scanlist_clean)
```

*Keeping data long for now for mixed random effects model!*

# Adding Covariates

## Demographics
Adding sex, DOB/age, race (csv adapted from 7T list from David).

```{r}
#load demographics (adapted from 7T list from David)
demo.phi <- read.csv("data/7t_demographics.csv", header = TRUE, stringsAsFactors = TRUE, na = c("", "..", ".")) %>%
  mutate(sex = as.factor(Sex_1M),
         Ethnicity = as.factor(Ethnicity),
         DOB = as.Date(DOB, format = "%m/%d/%y"),
         BBLID = as.factor(BBLID)) %>%
 dplyr::select(-Diagnostic_Group, -sex, -Age)

sops_demo.phi <- left_join(scanlist_clean, demo.phi, by="BBLID")
#skim(sops_demo.phi)
n_unique(sops_demo.phi$observation)
```

Demographic variables have 100% completion.

Using DOB to calculate age at scan and at endpoint SOPS, then removing.

```{r}
sops_demo <- sops_demo.phi %>%
  mutate(age_scan = as.numeric(difftime(date7t,DOB, units = "weeks"))/52.25,
         age_sops = as.numeric(difftime(DOSIPS,DOB, units = "weeks"))/52.25) %>%
 dplyr::select(-DOB)

summary(sops_demo$age_scan)
summary(sops_demo$age_sops)
```

## Diagnosis

Now merge in diagnosis and filter to smallest datediff

```{r}
#get just dates/matching info for observations
just_scans <- sops_demo %>%dplyr::select(BBLID, observation, DOSIPS, date7t, scan.time)

sops_dx <- left_join(just_scans, redcap, by="BBLID")
any(is.na(sops_dx$AXIS1_DX1)) #no primary dx missing

#calculate datediff from dx to sops, keep just row closest
sops_dx.filt <- sops_dx %>%
  mutate(dx_sops_diff = as.numeric(difftime(DODIAGNOSIS,DOSIPS, units = "days"))) %>%
  arrange(abs(dx_sops_diff)) %>%
  group_by(observation) %>%
  slice_head() %>% #keep only closest dx
  ungroup() %>%
  filter(abs(dx_sops_diff) <= 100) %>% #restrict to w/in 100 days
 dplyr::select_if(~!all(is.na(.)))

sops_dx.filt %>% 
  ggplot(aes(x=dx_sops_diff, fill=scan.time)) + geom_bar() + facet_grid(cols = vars(scan.time))

#focusing on baseline
sops_dx.filt %>% filter(scan.time=="base.1") %>%
  mutate(dx_to_scan_diff = as.numeric(difftime(DODIAGNOSIS,date7t, units = "days"))) %>%
  ggplot(aes(x=dx_to_scan_diff)) + geom_dotplot()

#merge back in
n_unique(sops_dx.filt$observation)
summary(sops_dx.filt$dx_sops_diff)
#skim(sops_change_dx)
```

Now merge back in

```{r}
#drop stuff that's already there before merging
sops_dx.filt <- sops_dx.filt %>%
 dplyr::select(-BBLID, -DOSIPS, -date7t, -scan.time)

sops_dx.final <- left_join(sops_demo, sops_dx.filt, by="observation")
#skim(sops_dx.final)
n_unique(sops_dx.final$observation)
```

First I'll make an indicator for psychosis/prodrome at baseline or endpoint (since `HSTATUS` cols aren't really great).

```{r}
sops_dx.final %>%dplyr::select(contains("AXIS1_DX")) %>% 
  t %>% c %>% unique
control.list <- c("V71.09B")
pro.list<- c("348.4", "348.43", "348.62", "348.42", "348.12", "348.41", "348.11")
psych.list <- c("295.6", "298.9", "295.4", "295.9")
other.list <- c("300", "300.23", "311", "309.21", "304.3", "296.35", "V62.82", "309.81", "300.02", "305", "296.36", "303.9", "296.32", "314", "296.25", "296.2", "296.26", "300.3", "296.9", "314.01", "799.90B")

#making indicator for each dx category
sops_dx.sum <- sops_dx.final %>% 
  mutate(dx_control = if_any(starts_with("AXIS1_DX"), ~ .x %in% control.list,1,0),
         dx_pro = if_any(starts_with("AXIS1_DX"), ~ .x %in% pro.list,1,0),
         dx_psych = if_any(starts_with("AXIS1_DX"), ~ .x %in% psych.list,1,0),
         dx_other = if_any(starts_with("AXIS1_DX"), ~ .x %in% other.list,1,0)) %>%
  mutate(diagnosis = as.factor(case_when(dx_pro == TRUE ~ "pro", #single col of dx
                                 dx_psych == TRUE ~ "psych",
                                 dx_other == TRUE ~ "other",
                                 dx_control == TRUE ~ "none")))

#adding a base_dx indicator, since if we're predicting outcomes we'd know this (though maybe v correlated with intercept)

sops_dx.sum <- sops_dx.sum %>%
  group_by(BBLID, SCANID) %>%
  mutate(base_dx=first(diagnosis),
         base_gafc=first(GAF_C),
         base_sops_p=first(sops_p),
         delta_sops=sops_p-base_sops_p,
         sops_cat = as.factor(case_when(delta_sops<0 ~ "remit",
                                        delta_sops==0 ~ "stable",
                                        delta_sops>0 ~ "progress")))%>%
  ungroup()

sops_dx.sum %>% 
  ggplot(aes(y=BBLID, x=scan.time, color=diagnosis)) + geom_point()
```

Diagnosis amongst baseline prodromal and psychotic disorder subjects seem to be largely stable over time.

And drop all the extra dx columns we don't need

```{r}
sops_dx.sum.filt <- sops_dx.sum %>%
 dplyr::select(!contains("AXIS1") & !contains("HSTATUS") & !contains("CONSIDER") & !contains("PRODROMAL") & !contains("POSS_PRO_DX"))
```


## Medication Info

Load and clean med data

```{r}
#load med data
meds <- read.csv("data/oracle_meds_all.csv", header = TRUE, stringsAsFactors = F, na = c("", "null"))
skim(meds)

#each med is it's own row, so need to rotate wide
meds <- meds %>%
  group_by(BBLID, DOCOLLECT) %>%
  mutate(ID = paste(as.character(BBLID), as.character(DOCOLLECT)), #col to ID subj+timepoint
         count = row_number(), #count meds entered
         DOCOLLECT= as.Date(DOCOLLECT)) %>% 
  ungroup()

hist(meds$count)

medswide <- meds %>%
 dplyr::select(BBLID, DOCOLLECT, ID, count, MEDICINE, NOTES, IS_CURRENT) %>%
  mutate(BBLID=as.factor(BBLID)) %>%
  pivot_wider(., names_from = count, values_from=c(MEDICINE, NOTES, IS_CURRENT)) # pivot

#get subset
meds_reduced <- meds %>%
 dplyr::select(BBLID, DOCOLLECT, MED_COLLECT, NOTES, MEDICINE, PHARMCLASS, DOMED_START, DOMED_END, IS_CURRENT)
```

Trying to add PNC data to see if that will help get more baseline info

```{r}
pnc.meds <- read.csv("data/n1601_health_with_meds_20170421.csv", header = TRUE, stringsAsFactors = F, na ="") %>%
  mutate(BBLID=as.factor(bblid)) %>%
 dplyr::select(-bblid)
skim(pnc.meds)

#get managable subset of scan list
scan_dates <- sops_dx.sum.filt %>%
 dplyr::select(BBLID, date7t, observation) %>%
  distinct()

pnc.meds_scan_date <- inner_join(scan_dates, pnc.meds, by="BBLID") %>%
  distinct(observation, .keep_all = T)
n_unique(pnc.meds_scan_date$BBLID)
```

Inferring based on PNC data collection window that all meds are within study range, will add into lifetime calculations. 

Lets go back and look at lifetime:

```{r}
#merge with scan lists
med_dates <- inner_join(just_scans, meds_reduced, by="BBLID")
n_unique(med_dates$observation)

med_lifetime <- med_dates %>%
  group_by(observation) %>%
  mutate(meds_sops_diff=as.numeric(difftime(DOCOLLECT, DOSIPS, units = "days"))) %>% #DOCOLLECT - DOSIPS, so if + then DOCOLLECT is after SOPS
  filter((is.na(DOMED_START) & meds_sops_diff <= 100) | DOSIPS >= DOMED_START) %>% #keep if med is STARTED BEFORE SOPS (or start date unknown but collect is no later than 100 days after)
  mutate(count = row_number()) %>% #add counts so i can pivot after
  ungroup()
  
med_lifetime$MEDICINE[is.na(med_lifetime$MEDICINE)] <- "empty entry"
skim(med_lifetime)

#trying to find distinct meds for each observation
med_lifetime_dist <- med_lifetime %>%
  group_by(observation) %>%
  distinct(MEDICINE, .keep_all = T) %>% #keep distinct
  mutate(count=row_number()) %>% #update counts so i can pivot after
  ungroup() %>%
 dplyr::select(BBLID, DOSIPS, observation, MEDICINE, NOTES, count)
table(med_lifetime_dist$MEDICINE)

#pivot
med_lifetime_dist.wide <- pivot_wider(med_lifetime_dist, id_cols=observation, names_from = count, values_from=c(MEDICINE, NOTES)) %>% # pivot
 dplyr::select_if(~!all(is.na(.))) #drop any col that's totally empty
n_unique(med_lifetime_dist.wide$observation)
n_unique(med_lifetime_dist$BBLID)
```

If an individual only has `empty entry` value then we can infer that they are not taking any medications. Restricting to either date of collection no later than 100 days post-SOPS OR medicaiton being noted as starting before the SOPS date, there's med info for all subjects but not for all observations.

Integrate PNC meds:

```{r}
pnc.meds.only <- pnc.meds_scan_date %>%
 dplyr::select(observation, 22:32)
pnc.meds.only$med1[is.na(pnc.meds.only$med1)] <- "empty entry"

med_lifetime_comp <- full_join(med_lifetime_dist.wide, pnc.meds.only, by="observation")

#check if any observations are still missing med info:
med_lifetime_comp %>% filter(is.na(MEDICINE_1) & is.na(med1)) %>% nrow
```

Yay, no observations are unaccounted for. Save out and manually code for psych rx:

```{r}
write.csv(med_lifetime_comp, "data/med_lifetime_comp.csv", row.names=FALSE, na="")
```

Read back in and merge coded lifetime meds:

```{r}
meds.coded <- read.csv("data/med_lifetime_comp.CODED.csv", header = TRUE, stringsAsFactors = F, na="") %>%
 dplyr::select(observation, psych.rx_life) %>%
  mutate(psych.rx_life=as.factor(psych.rx_life))

sops_change_meds.life <- left_join(sops_dx.sum.filt, meds.coded, by="observation")
sops_change_meds.life <- sops_change_meds.life %>%
  group_by(BBLID, SCANID) %>%
  mutate(base_rx=first(psych.rx_life)) %>%
  ungroup()

n_unique(sops_change_meds.life$observation)
#skim(sops_change_meds.life)
```


# CEST values

Read in processed CEST values from Harvard Oxford Subcortical Atlas ROIs:

```{r}
cest.rois <- read.csv("data/GluCEST-HarvardOxford-Subcortical-Measures.csv", header = TRUE, stringsAsFactors = F, sep = '\t', na="NaN")
skim(cest.rois)

#clean up a bit
cest.vals <- cest.rois %>%
 dplyr::select_if(~!all(is.na(.))) %>% #drop any col that's totally empty
  mutate(scanid = str_split(as.character(Subject), "/", simplify = T)[, 6]) %>% #get BBLID_scanID 
 dplyr::select(-Subject)

#GM voxels
cest.gm.rois <- read.csv("data/GM-HarvardOxford-Subcortical-Measures.csv", header = TRUE, stringsAsFactors = F, sep = '\t', na="NaN")

#clean up a bit
gm.vals <- cest.gm.rois %>%
 dplyr::select_if(~!all(is.na(.))) %>% #drop any col that's totally empty
  mutate(scanid = str_split(as.character(Subject), "/", simplify = T)[, 6]) %>% #get BBLID_scanID 
 dplyr::select(-Subject) %>%
  rename_with(.cols = 1:(ncol(.)-1), function(x){paste0("gm.", x)}) #add prefix
```

ALL SCANS HAVE RIGHT THALAMUS DATA!

one subject also weirdly has GM values in `L_CerebralWM_mean`, outputting scan ID so I can look at the niftis

```{r}
gm.vals %>% filter(!is.na(gm.L_CerebralWM_numvoxels)) %>%dplyr::select(scanid, gm.L_CerebralWM_numvoxels)
```

Looks like slab was placed across the midline, seeing if other scans have comparable gm voxels in `R_CerebralWM_mean` as comparison.

```{r}
gm.vals %>% filter(!is.na(gm.R_CerebralWM_numvoxels)) %>%dplyr::select(scanid, gm.R_CerebralWM_numvoxels)
```

Seems like having errant GM voxels (calculated probablistically via FAST) isn't uncommon in WM (as defined by HO Subcortical atlas), what makes 94276_10927 unique is slab orientation. 

Merging cest values, remove wonky mOFC data and filter to thalamic ROI

```{r}
all.cest <- merge(cest.vals, gm.vals, by="scanid") %>%
  filter(!scanid %in% c("105176_9332", "132179_9726", "92886_9087", "87225_9459", "94028_9203"))

sum(duplicated(all.cest$BBLID)) #no duplicate subjects remain

r.thal.dat <- all.cest %>%dplyr::select("scanid" | contains("R_Thalamus"))
skim(r.thal.dat)

r.thal.dat %>%dplyr::select(-scanid) %>% ggpairs()

#check for correlation of thalamic volume captured and avg. CEST
cor.test(r.thal.dat$R_Thalamus_mean, r.thal.dat$R_Thalamus_numvoxels, method=c("pearson"))
```

# Final Dataframe

Merging into other *FINAL DATASET*

```{r}
clin.to.merge <- sops_change_meds.life %>%
  mutate(scanid=paste(BBLID, SCANID, sep="_"))

final.df <- right_join(clin.to.merge, r.thal.dat, by="scanid")
n_unique(final.df$observation)
n_unique(final.df$BBLID)

#scaled dataframe
final.df_scaled <- final.df %>% mutate_if(is.numeric, scale)

#baseline only
final.base <- final.df %>% filter(scan.time=="base.1") %>%
  mutate(sex=recode_factor(Sex_1M, `1`="Male", `2`="Female"))

#followups only 
final.end <- final.df %>% filter(scan.time != "base.1")

#followups only - scaled
final.end_scaled <- final.end %>% mutate_if(is.numeric, scale)
```

# EDA

Plotting correlations 

```{r fig.width=20, fig.height=20}
skim(final.df)

final.df %>% 
 dplyr::select_if(is.numeric) %>%
  cor(., use = "pairwise.complete.obs") %>%
  corrplot(method = "color", 
           type = "upper",
           addCoef.col = "black", # Add coefficient of correlation
           tl.col="black", tl.srt = 45, #Text label color and rotation
           # hide correlation coefficient on the principal diagonal
           diag = FALSE 
           )
```

Some basic demographic info on the entire sample:

```{r, warning=FALSE}
summary(final.df$age_sops)
summary(final.df$age_scan)

p.age_scan <- final.df %>%
  ggplot() + 
  geom_histogram(aes(x = age_scan), fill="cadetblue4") +
  ggtitle("Age at Scan")

p.age_sops <- final.df %>%
  ggplot() + 
  geom_histogram(aes(x = age_sops), fill="darkslateblue") +
  ggtitle("Age at SOPS")

age_plot <- ggarrange(p.age_scan, p.age_sops, common.legend = F, legend = "bottom", ncol = 2)
annotate_figure(p=age_plot, top = text_grob("Age of Participants at Scan and Clinical Assessments", 
                               color = "black", face = "bold", size = 14))
```

Visualize spread of followup timepoints for possible future binning:

```{r}
final.end %>%
  ggplot() + 
  geom_histogram(aes(x = sips_diff_days), fill="darkseagreen4", color="white", bins=10) +
  ggtitle("Time to Clinical Follow-Up")

#10 looks like good # of bins
final.bin_scaled <- final.end %>%
  mutate(sips_diff_bin=ntile(sips_diff_days, n=10)) %>%
  mutate_if(is.numeric, scale)
```


## Between-Scanner Differences

### Baseline Demographics and Observation Counts

```{r}
demo <- final.df %>% filter(scan.time=="base.1") %>%
  group_by(scanner) %>%
  summarise(n = n(),
            age=mean(age_scan),
            age_sd=sd(age_scan))

demo.base <- atable(final.base, 
         target_cols=c("sex", "age_scan", "Race", "Ethnicity", "base_dx", "TYPE", "base_sops_p", "base_gafc", "psych.rx_life"),
         group_col="scanner",
         format_to="HTML")

tpt.table <- atable(final.df,
                    target_cols=c("scan.time", "age_sops", "sips_diff_yrs", "diagnosis", "sops_p", "sops_n", "sops_d", "sops_g", "GAF_C", "psych.rx_life"),
                    group_col="scanner",
                    format_to="HTML")
```

### CEST Values

Compare Thalamic CEST data by scanner:

```{r}
final.df %>%dplyr::select(scanner | contains("Thalamus")) %>% ggpairs(aes(color=scanner))

cest.table <- atable(final.base,
       target_cols=c("R_Thalamus_mean", "R_Thalamus_numvoxels", "gm.R_Thalamus_mean", "gm.R_Thalamus_numvoxels"),
       group_col="scanner",
       format_to = "HTML")
```

### Significance Testing

Are CEST values or demographics significantly different between scanners?

```{r}
#check for differences in baseline diagnoses
chisq.test(final.base$scanner, final.base$base_dx, simulate.p.value=TRUE)
#check for differences in scan age
chisq.test(final.base$scanner, final.base$age_scan, simulate.p.value=TRUE)
#check for differences in baseline SOPS Positive
t.test(base_sops_p ~ scanner, data=final.base)

#check for differences in thalamic CEST
t.test(R_Thalamus_mean ~ scanner, data = final.base)
#check for differences in thalamic volume captured
t.test(R_Thalamus_numvoxels ~ scanner, data = final.base)

#look for correlations between volume and CEST when controlling for scan
m.cest.vol <- lm(R_Thalamus_mean ~ scanner + R_Thalamus_numvoxels, data=final.base)
summary(m.cest.vol)
Anova(m.cest.vol)
```

Scanner is *not significantly* related to baseline diagnosis, baseline SOPS positive score, or age at scan but *is significantly* related to CEST contrast (averaged over thalamus) and number of thalamic volumes captured. After controlling for scanner, number of voxels *is not* significantly associated with mean CEST value in the thalamus, therefore scanner (but not volume) will be controlled for in the final model.

## Clinical Values

Look at correlations between lifetime psych rx and diagnosis - unsurprisingly these are highly correlated values

```{r}
kruskal.test(final.df$psych.rx_life~final.df$diagnosis)

ggplot(final.df) + 
  geom_count(aes(x = factor(diagnosis), y = as.factor(psych.rx_life))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("SOPS Total Score vs Axis 1 Dx")

final.df %>% 
  group_by(BBLID) %>%
  ggplot(aes(x = diagnosis, y = sops_p, color=psych.rx_life)) +
  geom_point(aes(color=psych.rx_life), show.legend = TRUE) +
  geom_jitter(width = 0.25) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ggtitle("SOPS Positive Score vs Axis 1 Dx")
```

```{r}
t.test(sops_p ~ psych.rx_life, data = final.df)

final.df %>%
  group_by(BBLID, SCANID) %>%
  mutate(base_rx=first(psych.rx_life)) %>%
  t.test(sops_p ~ base_rx, data = .)
```


Higher SOPS P scores are predictably related to psychosis diagnosis and psychiatric medication.

Look at CEST data by diagnosis and diagnostic category:

```{r}
#plots
final.base %>% dplyr::select(base_dx | contains("Thalamus")) %>% 
  filter(base_dx != "other") %>% #too few other dx, need to remove
ggpairs(aes(color=base_dx)) +
  ggtitle("Thalamic Cest Values by Baseline Diagnosis")

final.base %>%
 dplyr::select(dx_control | contains("Thalamus")) %>% 
  mutate(dx_control=recode_factor(as.factor(dx_control), 'TRUE'="Control", 'FALSE'="Patient")) %>%
  ggpairs(aes(color=dx_control)) +
  ggtitle("Thalamic Cest Values: Patients vs Controls")

#linear model
lm.dx <- lm(R_Thalamus_mean ~ scanner + base_dx + Sex_1M + age_scan, data=final.base)
summary(lm.dx)
Anova(lm.dx)
```

Overall, baseline diagnosis does not appear to be significantly associated with thalamic cest when controlling for sex, age and scanner type, while scanner type does remain predictive.

Looking at baseline diagnosis vs GAF

```{r}
ggplot(final.df, aes(x=sips_diff_days, y=GAF_C, color=base_dx)) +
  geom_point() +
  xlab("Time from Scan") +
  ylab("GAF") + 
  ggtitle("GAF Progression by for Each Dx Category") + 
  geom_smooth(method="lm") +
  theme_bw()

sum(is.na(final.df$GAF_C))
```

```{r}
ggplot(final.df, aes(x=sips_diff_days, y=sops_p, color=base_dx)) +
  geom_point() +
  xlab("Time from Scan") +
  ylab("SOPS Positive Score") + 
  ggtitle("SOPS-P Progression by for Each Dx Category") + 
  geom_smooth(method="lm") +
  theme_bw()
```

All groups appear to have relatively stable SOPS-P scores when averaged across individuals. But can CEST values predict and individual's change?

```{r}
ggplot(final.df, aes(x=sips_diff_days, y=sops_p, color=BBLID)) +
  geom_line() +
  xlab("Time from Scan") +
  ylab("SOPS Positive Score") + 
  ggtitle("SOPS-P Progression by for Each Subject") + 
  geom_smooth(method="lm",se = FALSE) +
  theme_bw()
```

```{r}
#plot of change by dx
final.end_scaled %>%
  ggplot() + 
  geom_histogram(aes(x = delta_sops, fill=base_dx, color=base_dx), position="dodge", alpha=0.5) +
  ggtitle("Change in SOPS Positive Score by Baseline Diagnosis")
```

Plot change in sops positive by glutamate (similar to egerton et al fig 2)

```{r}
final.end_scaled %>%
  filter(base_dx=="pro"| base_dx=="psych")
ggplot(data = final.end_scaled, mapping = aes(x = R_Thalamus_mean, y = delta_sops)) +
  geom_point(na.rm = T, aes(col = diagnosis)) +
  geom_smooth(method = "lm", na.rm=T, col = "black", se=T) +
  theme(legend.position = "right") +
  labs(title="Thalamic Glutamate by Change in SOPS Positive \n Among Prodrome and Psychosis Pts (Scaled)",
        x ="Thalamic Glutamate Contrast", y = "Change in SOPS Positive", color="Endpoint Diagnosis")
```

The plot is vaguely suggestive of that in Egerton et al, but clearly not significant. However, these are scaled raw values while their plot reported "Baseline thalamic glutamate level, adjusted for baseline attenuated positive symptom score".

# Modeling

Plotting simple linear model for visualization.

```{r}
ggplot(data = final.df, mapping = aes(x = sips_diff_days, y = sops_p)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_smooth(method = "lm", na.rm = T, col = "black", se = F) +
  theme(legend.position = "right")
```
At the population level, SOPS Positive scores remained stable over time.

Lm to look for any interactions of thalamic CEST and diagnosis:

```{r}
lm.int <- lm(sops_p ~ R_Thalamus_mean*base_dx, data=final.df)
Anova(lm.int)

lm.int2 <- lm(sops_p ~ R_Thalamus_mean*R_Thalamus_numvoxels, data=final.df)
Anova(lm.int2)

lm.int3 <- lm(sops_p ~ R_Thalamus_mean*sips_diff_days, data=final.df)
Anova(lm.int3)
```

No evidence of meaningful interactions that should be included in the final model. 

## Mixed Effects Models of SOPS P Change

Using scaled data so model will converge more readily. No need for random slopes, since each subject's `delta_sops` allows for varying clinical trajectories all on their own. Slope in this case will be analogous to the relationship between cest and improvement, which we hope will be the same/generalizable across subjects, rather than between cest and scores.

```{r}
fit.delta.1 <- lmer(delta_sops ~ sips_diff_days + (1|BBLID), REML = T, data = final.end_scaled )
summary(fit.delta.1)

#plot
delta1_coefs <- coef(fit.delta.1)$BBLID %>% 
  rename(Intercept = `(Intercept)`, Slope = sips_diff_days) %>% 
  rownames_to_column("BBLID")

model.end.1.data <- left_join(final.end_scaled, delta1_coefs, by="BBLID")

ggplot(data = model.end.1.data, mapping = aes(x = sips_diff_days, y = delta_sops)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = BBLID
                  ),
              size = 0.5
              ) +
  theme(legend.position = "right")
```

Adding baseline SOPS P to model

```{r}
fit.delta.2 <- lmer(delta_sops ~ sips_diff_days + base_sops_p + (1|BBLID), REML = T, data = final.end_scaled)
summary(fit.delta.2)
```

Adding demographics

```{r}
fit.delta.3 <- lmer(delta_sops ~ Sex_1M + age_scan + base_sops_p + sips_diff_days + (1 |BBLID), REML = T, data = final.end_scaled)
summary(fit.delta.3)
#Anova(fit.delta.3)
```

Adding in CEST values along with scanner, since Thalamic glucest contrast varies significantly between scanner.

```{r}
fit.delta.4 <- lmer(delta_sops ~ R_Thalamus_mean + scanner + Sex_1M + age_scan + base_sops_p + sips_diff_days + (1 |BBLID), REML = T, data = final.end_scaled )
summary(fit.delta.4)
#Anova(fit.delta.4)

#plot
delta4_coefs <- coef(fit.delta.4)$BBLID %>% 
  rename(Intercept = `(Intercept)`, Slope = sips_diff_days) %>% 
  rownames_to_column("BBLID")

model.end.4.data <- left_join(final.end_scaled, delta4_coefs, by="BBLID")

ggplot(data = model.end.4.data, mapping = aes(x = sips_diff_days, y = delta_sops)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = BBLID
                  ),
              size = 0.5
              ) +
  theme(legend.position = "right")
```

Visualizing relationship with 3D plot

```{r, warning=FALSE}
scatter3D(final.end_scaled$sips_diff_days, final.end_scaled$R_Thalamus_mean, final.end_scaled$delta_sops, colvar = final.end_scaled$R_Thalamus_mean, bty = "b2", col = NULL, add = FALSE, theta = 110, phi = 20, main = "", xlab = "Time", ylab ="Thalamic CEST", zlab = "Change in SOPS P")
plotrgl()
```

Given the small sample size, it's risky to add more predictors. However, we'll try just adding the indicator for lifetime psych medication at time of scan.

```{r}
fit.delta.5 <- lmer(delta_sops ~ R_Thalamus_mean + scanner + Sex_1M + age_scan + base_sops_p + sips_diff_days + base_rx + (1 |BBLID), REML = T, data = final.end_scaled )
summary(fit.delta.5)
#Anova(fit.delta.5)
```

Finally, I'll fit a full model without CEST data for comparison.

```{r}
fit.delta.6 <- lmer(delta_sops ~ Sex_1M + age_scan + base_sops_p + sips_diff_days + base_rx + (1 |BBLID), REML = T, data = final.end_scaled)
summary(fit.delta.6)
#Anova(fit.delta.6)
```

Using anova to compare nested model fits:

```{r}
anova(fit.delta.5, fit.delta.6, test="Chisq")
```

There is no significant difference between `fit.delta.5` and `fit.delta.6`, suggesting that adding thalamic CEST values do not improve the model. 

"The residual variance estimate can be thought of as the within groups variance and each random effect variance estimate can be thought of as a between groups estimate"

Diagnostics
```{r}
#linearity - plotting residuals
plot(fit.delta.6)
#normality - plotting quantiles
qqnorm(residuals(fit.delta.6))
```

Heteroscedastic - model fits less well at higher (and more important) sops_p score changes; adding `base_dx` to try to improve fit.

```{r}
fit.delta.7 <- lmer(delta_sops ~ Sex_1M + age_scan + base_sops_p + sips_diff_days + base_rx + base_dx + (1|BBLID), REML = T, data = final.end_scaled)
summary(fit.delta.7)
#Anova(fit.delta.7)

anova(fit.delta.6, fit.delta.7, test="Chisq")
```

Baseline dx does not appear to add to the fit of the model. 

## Progressors vs Remitters

Classifying each subject as progression vs remission based on whether trajectory from baseline to final endpoint SOPS-P is + or -, looking for between-group CEST differences (similar to Allen et al Fig 3A & binary logistic regression run in Egerton).

```{r}
#first subset df to final tp for each subject
end.df <- final.df %>%
  group_by(BBLID) %>%
  slice_tail() %>%
  ungroup() %>%
  mutate(sops_worse = case_when(sops_cat == "remit" ~ 0,
                                sops_cat == "stable" ~ 0,
                                sops_cat == "progress" ~ 1))

table(end.df$sops_worse) #pretty even split
fit.stat <- glm(sops_worse ~ R_Thalamus_mean + scanner, data=end.df, family=binomial(logit))
Anova(fit.stat)

#confirm that these results don't change when removing controls
end.df.pts <- end.df %>%
  filter(base_dx!= "none")
fit.stat.pt <- glm(sops_worse ~ R_Thalamus_mean + scanner, data=end.df.pts, family=binomial(logit))
Anova(fit.stat.pt)
```

Thalamic glutamate levels do not differ between remitters and progressors in our sample, whether or not controls are included in the sample.

```{r}
#controlling for clinical factors
fit.stat2 <- glm(sops_worse ~ R_Thalamus_mean + scanner + Sex_1M + age_scan + base_sops_p, data=end.df, family=binomial(logit))
Anova(fit.stat2)

#clinical factors only
fit.stat3 <- glm(sops_worse ~ Sex_1M + age_scan + base_sops_p + base_rx + base_rx, data=end.df, family=binomial(logit))
Anova(fit.stat3)
summary(fit.stat3)
```

Running partial correlations (as in Egerton et al) on baseline glutamate vs SOPS P ("Relationships between baseline glutamate concentrations and absolute change in attenuated psychotic symptoms or GAF score over time were calculated using partial correlation  coefficients,  co-varying  for  baselines cores to control for regression to the mean")

```{r}
pcor.df <- end.df %>%
  mutate(scan.num = case_when(scanner == "Terra" ~ 0,
                                scanner == "ONM" ~ 1)) %>% #must be numeric for pcor
  dplyr::select("base_sops_p", "sops_p", "sips_diff_days", "R_Thalamus_mean", "scan.num")

pcor(pcor.df, method="pearson")
```

No significant association of thalamic glutamate with final SOPS-P scores is found when controlling for baseline SOPS, time to endpoint, and scanner.

# Appendix

## References
+

## MEM Resources
+ UCLA [INTRODUCTION TO LINEAR MIXED MODELS](https://stats.oarc.ucla.edu/other/mult-pkg/introduction-to-linear-mixed-models/)
+ Bodo Winter's [Tutorial](https://bodowinter.com/tutorial/bw_LME_tutorial1.pdf)
+ Dr. Yury Zablotski's [yuzaR-Blog](https://bodo-winter.net/tutorials.html)
+ Using [REML](https://stats.stackexchange.com/questions/48671/what-is-restricted-maximum-likelihood-and-when-should-it-be-used)
+ Comparing models with [AIC](https://stats.stackexchange.com/questions/131272/lme4-why-is-aic-no-longer-displayed-when-using-reml)
+ interpreting summary [outputs](http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/Benchmarks/LinearMixedModels_JDS_Dec2010.pdf)
+ assessing [goodness of fit](https://stats.stackexchange.com/questions/37944/what-are-easy-to-interpret-goodness-of-fit-measures-for-linear-mixed-effects-mo), also [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5426279/)
+ repeated measures [info](https://landscape-agroecology.com/mixed-effects-models-in-r/)
+ random effects [correlation outputs](https://stats.stackexchange.com/questions/320978/understanding-and-coding-random-intercept-correlation-lmer)
+ random effects correlation, [specifically singularity when modeling a subject ID intercept and time slope](https://stat.ethz.ch/pipermail/r-help//2009-November/412590.html)

```{r, eval=FALSE}
tim=rep(10:19,10)
id=rep(1:10,each=10)
rand.int=rep(rnorm(10,0,1),each=10)
rand.slop=rep(rnorm(10,0,1),each=10)
e=rnorm(100,0,0.5)

y1=10+rand.int+tim+e
y2=10+rand.int+tim+e
y3=10+rand.int+tim+rand.slop*tim+e

reg1=lmer(y1~tim+(tim|id))
summary(reg1)

reg2=lmer(y2~tim+(tim|id))
summary(reg2)

#plot
reg2_coef <- coef(reg2)$id %>% 
  rename(Intercept = `(Intercept)`, Slope = tim) %>% 
  rownames_to_column("id")
y2.data <- data.frame(y2, tim, id) %>%
  mutate(id=as.character(id))
reg2.data <- left_join(y2.data, reg2_coef, by="id")

ggplot(data = reg2.data, mapping = aes(x = tim, y = y2)) +
  geom_point(na.rm = T, aes(col = id)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = id
                  ),
              size = 0.5
              )

reg2a=lmer(y2~tim+(1|id))
summary(reg2a)

#plot
reg2a_coef <- coef(reg2a)$id %>% 
  rename(Intercept = `(Intercept)`, Slope = tim) %>% 
  rownames_to_column("id")
reg2a.data <- left_join(y2.data, reg2a_coef, by="id")

ggplot(data = reg2a.data, mapping = aes(x = tim, y = y2)) +
  geom_point(na.rm = T, aes(col = id)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = id
                  ),
              size = 0.5
              )

reg2b=lmer(y2~tim+(-1+tim|id))
summary(reg2b)

#plot
reg2b_coef <- coef(reg2b)$id %>% 
  rename(Intercept = `(Intercept)`, Slope = tim) %>% 
  rownames_to_column("id")
reg2b.data <- left_join(y2.data, reg2b_coef, by="id")

ggplot(data = reg2b.data, mapping = aes(x = tim, y = y2)) +
  geom_point(na.rm = T, aes(col = id)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = id
                  ),
              size = 0.5
              )

reg3=lmer(y3~tim+(tim|id))
summary(reg3)

```

## Mixed Effects Models - Baseline Included

Using scaled data so model will converge more readily. Building models with predictors chosen based on a priori subject knowledge and relationships shown above, getting sequentially more complex to avoid overfitting. Building models inclusive of baseline scores will assess for relationships between thalamic cest and SOPS-P, allowing that relationship to vary linearly over time (random slope for `sips_diff_days`). However,  because the primary interest of the study is *change* in SOPS P sxs, we want baseline SOPS to be a predictor of final SOPS (or change in SOPS) not predicted necessarily. Basically, i'm not hypothesizing that the relationship between sops and cest will vary linearly over time by individual (though thats' maybe interesting?); more directly i want to know if later SOPS are related to CEST. 

```{r}
lmer.1 <- lmer(sops_p ~ sips_diff_days + (1|BBLID), REML = T, data = final.df_scaled)
summary(lmer.1)

#plot
model_coefs <- coef(lmer.1)$BBLID %>% 
  rename(Intercept = `(Intercept)`, Slope = sips_diff_days) %>% 
  rownames_to_column("BBLID")

model1.data <- left_join(final.df_scaled, model_coefs, by="BBLID")

ggplot(data = model1.data, mapping = aes(x = sips_diff_days, y = sops_p)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = BBLID
                  ),
              size = 0.5
              ) +
  theme(legend.position = "right")
```


```{r}
lmer.2 <- lmer(sops_p ~ base_dx + (1 + sips_diff_yrs|BBLID), REML = T, data = final.df_scaled )
summary(lmer.2)

#plot
model_coefs2 <- coef(lmer.2)$BBLID %>% 
  rename(Intercept = `(Intercept)`, Slope = sips_diff_yrs) %>% 
  rownames_to_column("BBLID")
model2.data <- left_join(final.df_scaled, model_coefs2, by="BBLID")

ggplot(data = model2.data, mapping = aes(x = sips_diff_yrs, y = sops_p)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = BBLID
                  ),
              size = 0.5
              ) +
  theme(legend.position = "right") +
  ggtitle("Model on Scaled Numeric Data")
```


Simple random slopes model `lmer(sops_p ~ (1 + sips_diff_yrs|BBLID), REML = T, data = final.df_scaled)` singular with correlation of -1, because ppts with higher intercepts have more negative slopes (i.e. worse baseline sxs -> generally more improvement). Adding `base_dx` term resolves this singularity (i.e. shakes up this colinearity) by (it seems) accounting for intercept values outside of the random effect of `BBLID`.

Adding standard demographics (sex and age at scan)

```{r}
lmer.3 <- lmer(sops_p ~ Sex_1M + age_scan + base_dx + (1 + sips_diff_days|BBLID), REML = T, data = final.df_scaled )
summary(lmer.3)
#Anova(lmer.3)

#plot

model_coefs3 <- coef(lmer.3)$BBLID %>% 
  rename(Intercept = `(Intercept)`, Slope = sips_diff_days) %>% 
  rownames_to_column("BBLID")

model3.data <- left_join(final.df_scaled, model_coefs3, by="BBLID")

ggplot(data = model3.data, mapping = aes(x = sips_diff_days, y = sops_p)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = BBLID
                  ),
              size = 0.5
              ) +
  theme(legend.position = "right") +
  ggtitle("Model on Scaled Numeric Data")
```

Adding in CEST values along with scanner, since Thalamic glucest contrast varies significantly between scanner.

```{r}
lmer.4 <- lmer(sops_p ~ R_Thalamus_mean + scanner + Sex_1M + age_scan + base_dx + (1 + sips_diff_days|BBLID), REML = T, data = final.df_scaled )
summary(lmer.4)
Anova(lmer.4)


#plot
model_coefs4 <- coef(lmer.4)$BBLID %>% 
  rename(Intercept = `(Intercept)`, Slope = sips_diff_days) %>% 
  rownames_to_column("BBLID")
model4.data <- left_join(final.df_scaled, model_coefs4, by="BBLID")
ggplot(data = model4.data, mapping = aes(x = sips_diff_days, y = sops_p)) +
  geom_point(na.rm = T, aes(col = BBLID)) +
  geom_abline(aes(intercept = Intercept, 
                  slope = Slope,
                  colour = BBLID
                  ),
              size = 0.5
              ) +
  theme(legend.position = "right") +
  ggtitle("Model on Scaled Numeric Data")
```

Given the small sample size, it's risky to add more predictors. However, we'll try just adding the lifetime psych medication indicator. 

```{r}
lmer.5 <- lmer(sops_p ~ R_Thalamus_mean + scanner + Sex_1M + age_scan + base_dx + psych.rx_life + (1 + sips_diff_days|BBLID), REML = T, data = final.df_scaled )
summary(lmer.5)
Anova(lmer.5)
```

Even though `psych.rx_life` is very predictive of `sops_p` at a given timepoint, is not so much a predictor of interest (since if you know whether someone is taking psychiatric meds you probably also know their positive sxs); it's included because we want to control for it when testing the significance of the other predictors (because meds may affect glucest contrast and/or sops positive score).

Switching out baseline sops positive (`base_sops_p`) for `base_dx` results in a singular fit.

```{r}
lmer.6 <- lmer(sops_p ~ R_Thalamus_mean + scanner + Sex_1M + age_scan + base_sops_p + psych.rx_life + (1 + sips_diff_days|BBLID), REML = T, data = final.df_scaled )
# summary(lmer.6)
# Anova(lmer.6)
```

Finally, I'll fit a full model without CEST data for comparison.

```{r}
lmer.7 <- lmer(sops_p ~ Sex_1M + age_scan + base_dx + psych.rx_life + (1 + sips_diff_days|BBLID), REML = T, data = final.df_scaled )
summary(lmer.7)
Anova(lmer.7)
```

Using anova to compare nested model fits:

```{r}
anova(lmer.4, lmer.5, test="Chisq")

anova(lmer.5, lmer.7, test="Chisq")
```

`lmer.5` (adding `psych.rx_life`) unsurprisingly significantly improved the fit significantly. There was no significant difference between `lmer.5` and `lmer.7`, suggesting that adding thalamic CEST values do not improve the model. 

"The residual variance estimate can be thought of as the within groups variance and each random effect variance estimate can be thought of as a between groups estimate"

Diagnostics
```{r}
#linearity - plotting residuals
plot(lmer.5)
#normality - plotting quantiles
qqnorm(residuals(lmer.5))
```

Heteroscedastic - model fits less well at higher (and more important) sops_p scores


## Calculating % Change
Removed because it resulted in irritating and uninterpretable inf values.

```{r, eval=FALSE}
sops_change <- sops_change %>% 
  group_by(bblid_scan) %>%
  arrange(scan.time) %>%
  mutate(pct.delta.sops_p = abs.delta.sops_p/first(sops_p)  * 100,
         pct.delta.sops_n = abs.delta.sops_n/first(sops_n)  * 100,
         pct.delta.sops_d = abs.delta.sops_d/first(sops_d)  * 100,
         pct.delta.sops_g = abs.delta.sops_g/first(sops_g)  * 100,
         pct.delta.sops_tot = abs.delta.sops_tot/first(sops_tot)  * 100,
         pct.delta.gacf = abs.delta.gafc/first(GAF_C)  * 100)
```

## Unused Med Dataframes

Merge and keep med info at time of scan as well as time of each SOPS endpoint assessment. 

```{r, eval=FALSE}
sops_change_meds <- left_join(sops_change_dx, medswide, by="BBLID")

#calculate datediff from meds to scan/SIPS
sops_change_meds <- sops_change_meds %>%
  mutate(meds_7t_diff = as.numeric(difftime(DOCOLLECT, date7t, units = "days")),
         meds_sops_diff = as.numeric(difftime(DOCOLLECT, DOSIPS, units = "days")))
#ok, now pull the baseline meds and set them aside for now
meds_baseline <- sops_change_meds %>%
  arrange(abs(meds_7t_diff)) %>%
  group_by(observation) %>%
  slice_head() %>% #keep only closest dx
  ungroup() %>%
 dplyr::select(observation, meds_7t_diff, DOCOLLECT | contains("MEDICINE_") | contains("NOTES_") | contains("IS_CURRENT_")) %>% #drop non-med stuff
 dplyr::select_if(~!all(is.na(.))) %>% #drop any col that's totally empty
  rename_with(.cols = 3:ncol(.), function(x){paste0("base.", x)}) #add prefix
#go back and filter down to endpoint meds
meds_end <- sops_change_meds %>%
  arrange(abs(meds_sops_diff)) %>%
  group_by(observation) %>%
  slice_head() %>% #keep only closest dx
  ungroup() %>%
 dplyr::select(observation, meds_sops_diff, DOCOLLECT | contains("MEDICINE_") | contains("NOTES_") | contains("IS_CURRENT_")) %>% #drop non-med stuff
 dplyr::select_if(~!all(is.na(.)))

#plots to see the range of closest med info
sops.med.p <- meds_end %>%
  ggplot() + 
    geom_histogram(aes(x = meds_sops_diff), position="identity", color="lightblue", fill="lightblue")
scan.med.p <- meds_baseline %>%
  ggplot() + 
    geom_histogram(aes(x = meds_7t_diff), position="identity", color="lightgreen", fill="lightgreen")
# put p1 and p2 together
ggarrange(sops.med.p, scan.med.p, common.legend = T, legend = "bottom", ncol = 2)
```

Ok, maybe let's restrict to +- 100 days and add back in. Also tried 200 days but didn't add anything

```{r, eval=FALSE}
#filter down
meds_baseline <- meds_baseline %>%
  filter(abs(meds_7t_diff) <= 100) %>%
  mutate(across(c(contains("MEDICINE_")), factor)) #also setting meds as factors to see frequency later
meds_end <- meds_end %>%
  filter(abs(meds_sops_diff) <= 100) %>%
  mutate(across(c(contains("MEDICINE_")), factor)) #also setting meds as factors to see frequency later


#merge base and end meds together
meds_filt <- full_join(meds_baseline, meds_end, by="observation")
sum(is.na(meds_filt$meds_7t_diff))
sum(is.na(meds_filt$meds_sops_diff))

#merging meds with sops_change_dx b/c sops_change_meds already has med stuff
sops_change_meds.final <- left_join(sops_change_dx, meds_filt, by="observation") 

#make sure no obs lost
n_unique(sops_change_meds.final$observation)
#skim(sops_change_meds.final)
```

Ok, now how to summarize all this medication info into one cohesive value

```{r, eval=FALSE}
#see how often each med is reported
sops_change_meds.final %>%
 dplyr::select(contains("MEDICINE")) %>%
  unlist() %>%
  table()
```

NOTES:
CARVEDILOL = beta blocker (anxiety?)
CLONIDINE = hypertension, ADHD?
DEXMETHYLPHENIDATE HYDROCHLORIDE = ADHD
NORETHINDRONE ACETATE = progestin
RANITIDINE = antihistamine/antacid
TRILOMARZIA = birth control
ALBUTEROL = asthma
DEXEDRINE = ADHD
DICLOFENAC = arthritis
ADVAIR = asthma

ideas - use 0,1 indicator for each class of medication at each timepoint? could be granular (asthma, allergies, stimulants) or more broad (psych_rx, other_rx)
- use that indicator but lifetime?

keep if start/end dates of med are < date > ?
lifetime indicator - dont filter by date assessed, just if date-rx-start is < endpoint date?

Test using the DOMED_START and DOMED_END to only capture meds that are explicitly current for 7T scan

```{r, eval=FALSE}
#merge
scan_date_med <- inner_join(scan_dates, meds_reduced, by="BBLID")

#ok, keep only rows where med is current to 7T
scan_date_med_current <- scan_date_med %>%
  filter(is.na(DOMED_START) | date7t > DOMED_START) %>% #keep if med is STARTED BEFORE 7t
  filter(is.na(DOMED_START) | date7t < DOMED_END) %>% #keep if med was ENDED AFTER 7t
  mutate(med_7t_diff = as.numeric(difftime(DOCOLLECT,date7t, units = "days"))) %>%
  filter(!(is.na(DOMED_START) & (abs(med_7t_diff) > 100))) %>%  #only keep NAs if DOCOLLECT is w/in 100 days of scan
  group_by(observation) %>%
  mutate(count = row_number()) %>% #add counts so i can pivot after
  ungroup() %>%
  rename_with(.cols = 4:ncol(.), function(x){paste0("base.", x)}) #add prefix
scan_date_med_current$base.NOTES[is.na(scan_date_med_current$base.NOTES)] <- "empty entry"
skim(scan_date_med_current)

#pivot wide
scan_meds_current_wide <- pivot_wider(scan_date_med_current, id_cols=observation, names_from = base.count, values_from=c(4:12))
#just keep essential cols
scan.meds.current_wide.filt <- scan_meds_current_wide %>%
 dplyr::select(observation | contains("MEDICINE_") | contains("NOTES_")) %>%
 dplyr::select_if(~!all(is.na(.))) #drop any col that's totally empty
```

In the meantime I'll try to find meds current to endpoint SOPs.

```{r, eval=FALSE}
#ok, keep only rows where med is current to 7T
end_date_med_current <- end_date_med %>%
  filter(is.na(DOMED_START) | DOSIPS > DOMED_START) %>% #keep if med is STARTED BEFORE SOPS end
  filter(is.na(DOMED_START) | DOSIPS < DOMED_END) %>% #keep if med was ENDED AFTER SOPS end
  mutate(med_sops_diff = as.numeric(difftime(DOCOLLECT, DOSIPS, units = "days"))) %>%
  filter(!(is.na(DOMED_START) & (abs(med_sops_diff) > 100))) %>%  #only keep NAs if DOCOLLECT is w/in 100 days of scan
  group_by(observation) %>%
  mutate(count = row_number()) %>% #add counts so i can pivot after
  ungroup()
end_date_med_current$NOTES[is.na(end_date_med_current$NOTES)] <- "empty entry"
skim(end_date_med_current)

#pivot wide
end_meds_current_wide <- pivot_wider(end_date_med_current, id_cols=observation, names_from = count, values_from=c(4:12))
#just keep essential cols
end.meds.current_wide.filt <- end_meds_current_wide %>%
 dplyr::select(observation | contains("MEDICINE_") | contains("NOTES_")) %>%
 dplyr::select_if(~!all(is.na(.))) #drop any col that's totally empty
```

This seems to be working, lets try merging baseline and endpoint meds and see what we have

```{r, eval=FALSE}
currentmeds <- right_join(scan.meds.current_wide.filt, end.meds.current_wide.filt, by="observation")
```

Actually very narrow range of meds here, but the `empty entry` notes indicate either no medications or no new medications. Therefore I'll need to look back at participant's former meds

#Wide Data

## Operationalizing Change

Ok, now we calculate change from baseline to each endpoint (absolute and slope). Change is defined as final score - baseline score, so a negative value means final<baseline which means sxs improved! (except GAFC, where positive -> sxs improved)

``` {r, eval=FALSE}
#calculate change
sops_change <- scanlist_clean %>% 
  group_by(bblid_scan) %>%
  arrange(scan.time) %>%
  mutate(abs.delta.sops_p = sops_p - first(sops_p), #change=final-baseline -> negative value means score improves!
         abs.delta.sops_n = sops_n - first(sops_n),
         abs.delta.sops_d = sops_d - first(sops_d),
         abs.delta.sops_g = sops_g - first(sops_g),
         abs.delta.sops_tot = sops_tot - first(sops_tot),
         abs.delta.gafc = GAF_C - first(GAF_C),
         delta.sops_time = as.numeric(difftime(DOSIPS,first(DOSIPS), units = "days")),
         slope.sops_p = abs.delta.sops_p/delta.sops_time,
         slope.sops_n = abs.delta.sops_n/delta.sops_time,
         slope.sops_d = abs.delta.sops_d/delta.sops_time,
         slope.sops_g = abs.delta.sops_g/delta.sops_time,
         slope.sops_tot = abs.delta.sops_tot/delta.sops_time,
         slope.gafc = abs.delta.gafc/delta.sops_time,
         observation = paste(bblid_scan, scan.time)) %>% #add unique ID for each BBLID-scan-endpoint#
  ungroup() %>%
 dplyr::select(!c(sops.item.list, sops_p, sops_n, sops_d, sops_g, sops_tot)) %>% #drop raw scores
  filter(!(scan.time=="base.1"))

#double check to make sure no endpoint scans come before baseline scans 
summary(sops_change$delta.sops_time)
#just one row per BBLID-scan-endpoint#
any(duplicated(sops_change$observation))
n_unique(sops_change$observation)

#fun plots
ggplot(sops_change, aes(x=slope.sops_tot)) + geom_histogram()
ggplot(sops_change, aes(x=slope.sops_n)) + geom_histogram()
ggplot(sops_change, aes(x=slope.gafc)) + geom_histogram()

scanlist_clean %>%
ggplot(aes(x = sips_diff_days, y = sops_tot, color = bblid_scan)) + 
    geom_line() + 
    theme_bw()
```

linear model for fun

```{r, eval=FALSE}
bs.fit <- lm(slope.sops_tot ~ PRODROMAL, data=sops_change)
Anova(bs.fit)
```
